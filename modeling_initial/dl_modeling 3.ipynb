{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 Tabnet Volume prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, pickle, warnings\n",
    "from pathlib import Path\n",
    "import os, random, time, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (accuracy_score, classification_report,\n",
    "                             confusion_matrix, precision_recall_fscore_support,\n",
    "                             mean_absolute_error, mean_squared_error, r2_score, precision_score, recall_score,f1_score)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED                = 1\n",
    "BATCH               = 64\n",
    "PATIENCE            = 15\n",
    "MIN_ROWS_PER_CLASS  = 3      \n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "\n",
    "DATA_PATH = Path(\"./data/processed_csv.csv\")\n",
    "assert DATA_PATH.exists(), \"processed_csv.csv not found!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH   = \"./data/processed_csv.csv\"\n",
    "BASE_FEATS = [\"a\",\"b\",\"c\",\"alpha\",\"beta\",\"gamma\"]\n",
    "TARGET     = \"vol\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(CSV_PATH).dropna(subset=BASE_FEATS+[TARGET]).copy()\n",
    "\n",
    "def analytic_volume(a,b,c,alpha,beta,gamma):\n",
    "    alpha,beta,gamma = np.deg2rad(alpha),np.deg2rad(beta),np.deg2rad(gamma)\n",
    "    cos_a,cos_b,cos_c = np.cos(alpha),np.cos(beta),np.cos(gamma)\n",
    "    rad = np.clip(1 - cos_a**2 - cos_b**2 - cos_c**2 + 2*cos_a*cos_b*cos_c, 0, None)\n",
    "    return a*b*c*np.sqrt(rad)\n",
    "\n",
    "df[\"v_formula\"] = analytic_volume(df[\"a\"],df[\"b\"],df[\"c\"],\n",
    "                                  df[\"alpha\"],df[\"beta\"],df[\"gamma\"])\n",
    "FEATS = BASE_FEATS + [\"v_formula\"]\n",
    "\n",
    "X = df[FEATS].values.astype(np.float32)\n",
    "y = np.log1p(df[TARGET].values.astype(np.float32)).reshape(-1,1)\n",
    "\n",
    "scaler = StandardScaler().fit(X[:, :6])\n",
    "X[:, :6] = scaler.transform(X[:, :6])\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 5.39955 | val_rmse: 1.4062700271606445|  0:00:03s\n",
      "epoch 10 | loss: 0.11155 | val_rmse: 0.2486400008201599|  0:00:43s\n",
      "epoch 20 | loss: 0.04678 | val_rmse: 0.18647000193595886|  0:01:23s\n",
      "epoch 30 | loss: 0.02938 | val_rmse: 0.22452999651432037|  0:03:06s\n",
      "epoch 40 | loss: 0.02146 | val_rmse: 0.1903499960899353|  0:04:09s\n",
      "epoch 50 | loss: 0.02066 | val_rmse: 0.17824000120162964|  0:04:51s\n",
      "epoch 60 | loss: 0.01417 | val_rmse: 0.10523000359535217|  0:05:40s\n",
      "epoch 70 | loss: 0.01182 | val_rmse: 0.15897999703884125|  0:06:39s\n",
      "epoch 80 | loss: 0.0106  | val_rmse: 0.08816000074148178|  0:07:21s\n",
      "epoch 90 | loss: 0.01069 | val_rmse: 0.10780999809503555|  0:08:06s\n",
      "epoch 100| loss: 0.00929 | val_rmse: 0.09359999746084213|  0:08:58s\n",
      "epoch 110| loss: 0.00795 | val_rmse: 0.10200999677181244|  0:09:45s\n",
      "\n",
      "Early stopping occurred at epoch 110 with best_epoch = 80 and best_val_rmse = 0.08816000074148178\n"
     ]
    }
   ],
   "source": [
    "reg = TabNetRegressor(\n",
    "    n_d=64, n_a=64, n_steps=5, gamma=1.5,\n",
    "    n_independent=2, n_shared=2, lambda_sparse=1e-4,\n",
    "    optimizer_fn=torch.optim.Adam, optimizer_params=dict(lr=1e-3),\n",
    "    mask_type=\"entmax\", seed=42, verbose=10,\n",
    "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "    scheduler_params={\"step_size\":50, \"gamma\":0.9},\n",
    ")\n",
    "\n",
    "reg.fit(\n",
    "    X_tr, y_tr,\n",
    "    eval_set=[(X_te, y_te)],\n",
    "    eval_name=[\"val\"],\n",
    "    eval_metric=[\"rmse\"],\n",
    "    max_epochs=400, patience=30,\n",
    "    batch_size=1024, virtual_batch_size=128,\n",
    "    num_workers=0, drop_last=False,\n",
    "    loss_fn=torch.nn.MSELoss()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TabNet  •  MSE=20.097  MAE=0.154  R²=-11.3015\n"
     ]
    }
   ],
   "source": [
    "y_pred_log = reg.predict(X_te).flatten()\n",
    "y_pred     = np.expm1(y_pred_log)\n",
    "y_true     = np.expm1(y_te.flatten())\n",
    "\n",
    "mse, mae, r2 = (mean_squared_error(y_true,y_pred),\n",
    "                mean_absolute_error(y_true,y_pred),\n",
    "                r2_score(y_true,y_pred))\n",
    "print(f\"\\nTabNet  •  MSE={mse:.3f}  MAE={mae:.3f}  R²={r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_dict = reg.history.history\n",
    "train_key = next(k for k in hist_dict if k.startswith(\"loss\"))\n",
    "val_key   = next(k for k in hist_dict if k.startswith(\"val_\"))\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(hist_dict[train_key], label=\"Train\")\n",
    "plt.plot(hist_dict[val_key],   label=\"Val\")\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"RMSE (log‑scale)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(x=y_true, y=y_pred, s=15, alpha=0.6)\n",
    "mx = max(y_true.max(), y_pred.max())\n",
    "plt.plot([0, mx], [0, mx], 'r--')\n",
    "plt.xlim(0, 8)\n",
    "plt.ylim(0, 8)\n",
    "plt.title(\"True vs Predicted\")\n",
    "plt.xlabel(\"True\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "res = y_true - y_pred\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.histplot(res, kde=True, bins=30, color=\"steelblue\")\n",
    "plt.title(\"Residual Distribution\")\n",
    "plt.xlabel(\"Residual\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlim(-12, 12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(x=y_pred, y=res, s=15, alpha=0.6)\n",
    "plt.axhline(0, ls='--', c='red')\n",
    "plt.title(\"Residuals vs Predicted\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Residual\")\n",
    "plt.xlim(-1, 6)\n",
    "plt.ylim(-4, 4)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fi = reg.feature_importances_\n",
    "plt.figure(figsize=(12, 8))\n",
    "ax = sns.barplot(x=fi, y=FEATS, palette=\"crest\")\n",
    "plt.title(\"TabNet Feature Importance\")\n",
    "plt.xlabel(\"Importance Score\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.xlim(0, max(fi) * 1.1)\n",
    "for i, val in enumerate(fi):\n",
    "    ax.text(val + 0.01 * max(fi), i, f\"{val:.2f}\", va='center', fontsize=9)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'Models' already exists.\n",
      "Directory 'Models\\Model 3' created successfully.\n",
      "Successfully saved model at Models\\Model 3\\Model 3 tabnet_volume.zip\n",
      "Model saved to tabnet_volume.zip\n"
     ]
    }
   ],
   "source": [
    "parent_dir    = \"Models\"\n",
    "model_name    = \"Model 3\"\n",
    "model_dir     = os.path.join(parent_dir, model_name)\n",
    "\n",
    "try:\n",
    "    os.mkdir(parent_dir)\n",
    "    print(f\"Directory '{parent_dir}' created successfully.\")\n",
    "except FileExistsError:\n",
    "    print(f\"Directory '{parent_dir}' already exists.\")\n",
    "except PermissionError:\n",
    "    print(f\"Permission denied: Unable to create '{parent_dir}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "try:\n",
    "    os.mkdir(model_dir)\n",
    "    print(f\"Directory '{model_dir}' created successfully.\")\n",
    "except FileExistsError:\n",
    "    print(f\"Directory '{model_dir}' already exists.\")\n",
    "except PermissionError:\n",
    "    print(f\"Permission denied: Unable to create '{model_dir}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "reg.save_model(os.path.join(model_dir, f\"{model_name} tabnet_volume\"))\n",
    "print(\"Model saved to tabnet_volume.zip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
